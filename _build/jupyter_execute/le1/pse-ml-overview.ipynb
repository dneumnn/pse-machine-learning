{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d513668",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad7c395",
   "metadata": {},
   "source": [
    "## What exactly is Machine Learning?\n",
    "\n",
    "In what follows, we will first approach **machine learning** from a historical perspective. It all started in the early 50s in the last century with a model of **brain cell interaction** in the book [The Organization of Behaviour](https://pure.mpg.de/rest/items/item_2346268_3/component/file_2346267/content) by [Donald Hebb](https://www.researchgate.net/publication/340474253_Donald_O_Hebb_and_the_Organization_of_Behavior_17_years_in_the_writing/link/5e93ec4c4585150839d9666d/download). Heeb's ideas about how the brain works were groundbreaking.\n",
    "\n",
    "Hebb wrote, \n",
    "\n",
    "> “When one cell repeatedly assists in firing another, the axon of the first cell develops synaptic knobs (or enlarges them if they already exist) in contact with the soma of the second cell.” \n",
    "\n",
    "\n",
    "If we translate Hebb’s ideas to artificial neurons, his model can be described as a way of altering the relationships between neurons: If two neurons fire at the same time, then the relationship between the two neurons strengthens, otherwise it decreases.\n",
    "\n",
    "\n",
    "The term **Machine Learning** was already used by Arthur Samuel between 1952 and 1959. At that time, he investigated the question of whether a computer can be enabled to do something without explicit instructions. Is a computer able to learn? That question leads to the first formal definition of machine learning:\n",
    "\n",
    "---\n",
    "\n",
    "**Definition** [Arthur Samuel (1959)](https://en.wikipedia.org/wiki/Arthur_L._Samuel):\n",
    "\n",
    "Machine Learning is the field of study that gives computers the ability to learn without explicity programmed.\n",
    "\n",
    "---\n",
    "\n",
    "An insight into his work is provided by his article [Some Studies in Machine Learning Using the Game of Checkers](http://people.csail.mit.edu/brooks/idocs/Samuel.pdf).\n",
    "\n",
    "In 1957 Rosenblatt introduced the **Perceptron**. He combined Donald Hebb’s model of brain cell interaction with Arthur Samuel’s machine learning efforts and created the perceptron, a machine for image recognition.\n",
    "\n",
    "Several decades later, Tom Mitchel specified machine learning in his **1997** definition:\n",
    "\n",
    "---\n",
    "\n",
    "**Definition**\n",
    "[Tom Mitchell (1997)](https://en.wikipedia.org/wiki/Tom_M._Mitchell)\n",
    "\n",
    "Machine Learning is the science that is \n",
    "\n",
    "> “concerned with the question of how to construct computer programs that automatically improve with experience,”. (Mitchell, 1997)\n",
    "\n",
    "> \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\" (Mitchel 1997)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c8cb8",
   "metadata": {},
   "source": [
    "## The essence of Machine Learning\n",
    "\n",
    "Building on this, [Yaser Abu-Mostafa](https://work.caltech.edu) describes the **essence of machine learning** very impressively in his [Machine Learning lecture](https://www.youtube.com/playlist?list=PLD63A284B7615313A) from **2012**. \n",
    "\n",
    "---\n",
    "\n",
    "Machine Learning is feasilble when:\n",
    "\n",
    "- A pattern exists.\n",
    "- And we are not able to pin it down. We do not know the maths or rules behind that pattern.\n",
    "- But we have a lot of meaningful data or observations that can be used to learn the hidden pattern.\n",
    "\n",
    "---\n",
    "\n",
    "![Learning from Data!](learning-from-data.png)\n",
    "\n",
    "Learning from data can be seen from a probabilistic or an numerical analytic perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecdf69b",
   "metadata": {},
   "source": [
    "## Software 2.0\n",
    "\n",
    "Andrej Karpathy introduced the term [Software 2.0](https://karpathy.medium.com/software-2-0-a64152b37c35) in **2017**. \n",
    "\n",
    "He refers to so-called neural networks, which are models from **Deep Learning** (we will get to know later):\n",
    "\n",
    "> \"they represent the beginning of a fundamental shift in how we write software. They are Software 2.0.\"\n",
    "\n",
    "He distinguishes software into software 1.0 and software 2.0. In software 1.0 we create programs by programming instructions in the common programming languages C, C++, C#, Java, ..., which is what software developers do every day. In his point of view, software 1.0 has a very low complexity, because we have to be able to describe its complexity explicitly in instructions. On the other hand, software 2.0 allows us to learn relationships that have such a high complexity that we cannot program them explicitly in instructions. we can not make them explicit:\n",
    "\n",
    "> \"In contrast, Software 2.0 can be written in much more abstract, human unfriendly language, such as the weights of a neural network. No human is involved in writing this code because there are a lot of weights (typical networks might have millions)...\" \n",
    "\n",
    "In software 2.0 we do not know the rules and cannot write them down explicitly as instructions. Software 2.0 learns its rules implicitly (by adjusting the weights of the neural network - we will come to that later).\n",
    "\n",
    "\n",
    "![Software 1.0 versus 2.0](Software2_0-Andrej_Karpathy-Medium.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cb9c57",
   "metadata": {},
   "source": [
    "## Our Building Blocks for Machine Learning\n",
    "\n",
    "To use Arthur Samuel's words, our goal in this lecture is to understand how to enable a computer to learn.\n",
    "To do this, we obviously need three elementary building blocks:\n",
    "- we start with **data**.\n",
    "- then we need a parameterized **model** that can explain the data, given an appropriate choice of parameters.\n",
    "- at least an evaluation procedure, the **loss** function, that allows us to adjust the parameters of our model.\n",
    "\n",
    "In the next section we will formulate the learning problem in the language of math. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}